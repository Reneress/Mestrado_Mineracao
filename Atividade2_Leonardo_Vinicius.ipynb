{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reneress/Mestrado_Mineracao/blob/main/Atividade2_Leonardo_Vinicius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Objetivos da Atividade üéØ\n",
        "\n",
        "Os principais objetivos da **Atividade 2** s√£o:\n",
        "\n",
        "- Aplicar diferentes algoritmos de classifica√ß√£o (**√Årvore de Decis√£o**, **Bagging**, **Boosting** e **Random Forest**).\n",
        "- Comparar os resultados dos algoritmos utilizando t√©cnicas de valida√ß√£o e medidas de desempenho, como **acur√°cia** e **F1-Score**.\n",
        "- Transformar o problema multiclasse em problemas bin√°rios utilizando as abordagens **OVA (One-vs-All)** e **OVO (One-vs-One)**.\n",
        "- Realizar o ajuste de hiperpar√¢metros para o algoritmo de melhor desempenho, verificando o impacto no resultado final.\n",
        "\n",
        "## 2. Descri√ß√£o do Dataset üìä\n",
        "\n",
        "Para esta atividade, foi utilizado o dataset **\"Estimation of Obesity Levels Based On Eating Habits and Physical Condition\"**, que cont√©m informa√ß√µes sobre os n√≠veis de obesidade de indiv√≠duos a partir de seus h√°bitos alimentares e condi√ß√µes f√≠sicas. Este conjunto de dados foi extra√≠do de tr√™s pa√≠ses: **M√©xico**, **Peru** e **Col√¥mbia**, e possui um total de **2111 inst√¢ncias** e **17 atributos**.\n",
        "\n",
        "### 2.1. Caracter√≠sticas do Dataset\n",
        "\n",
        "- **Tamanho do Dataset**: 2111 amostras.\n",
        "- **N√∫mero de Atributos**: 16 caracter√≠sticas preditivas e 1 vari√°vel alvo (**NObeyesdad**, que representa o n√≠vel de obesidade).\n",
        "- **Natureza das Vari√°veis**: As vari√°veis incluem tanto caracter√≠sticas **categ√≥ricas** (por exemplo, **G√™nero**, **Hist√≥rico Familiar de Obesidade**) quanto **num√©ricas** (como **Idade**, **Peso**, **Altura**).\n",
        "\n",
        "### 2.2. Classes Alvo üî¢\n",
        "\n",
        "A vari√°vel alvo (**NObeyesdad**) √© uma vari√°vel categ√≥rica que representa o n√≠vel de obesidade dos indiv√≠duos e √© composta pelas seguintes classes:\n",
        "\n",
        "1. **Insufficient Weight**\n",
        "2. **Normal Weight**\n",
        "3. **Overweight Level I**\n",
        "4. **Overweight Level II**\n",
        "5. **Obesity Type I**\n",
        "6. **Obesity Type II**\n",
        "7. **Obesity Type III**\n",
        "\n",
        "### 2.3. Aplica√ß√£o Pr√°tica do Dataset\n",
        "\n",
        "Este dataset √© ideal para a tarefa de classifica√ß√£o multiclasse, onde buscamos estimar o n√≠vel de obesidade dos indiv√≠duos com base em seus h√°bitos alimentares e f√≠sicos. A tarefa envolvida nesta atividade permite explorar diferentes abordagens de classifica√ß√£o e t√©cnicas de transforma√ß√£o de problemas multiclasse em bin√°rios (OVA e OVO), o que √© fundamental para a compreens√£o de como os algoritmos se comportam em diferentes cen√°rios.\n",
        "\n",
        "## 3. Conclus√£o üìå\n",
        "\n",
        "A **Atividade 2** proporciona uma oportunidade valiosa de aplicar algoritmos de machine learning a um problema real, utilizando dados relacionados √† sa√∫de p√∫blica. O dataset escolhido oferece uma complexidade adequada para o estudo de algoritmos de classifica√ß√£o, especialmente em um contexto multiclasse, permitindo uma an√°lise aprofundada do desempenho dos modelos e suas respectivas abordagens (OVA e OVO).\n"
      ],
      "metadata": {
        "id": "5SDQXwnqwfM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FbAG7mz4wnw",
        "outputId": "95b3a727-054e-4315-a177-91ae9f1b898a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "RK8MtJUo5M98"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregar Conjunto de Dados"
      ],
      "metadata": {
        "id": "BcXE-4Wy7TJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Mestrado/Mineracao/Atividade 2/Base de dados/ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "\n",
        "\n",
        "\n",
        "# transformar as classes categ√≥ricas em num√©ricas\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Identificar colunas categ√≥ricas\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Aplicar o LabelEncoder a todas as colunas categ√≥ricas\n",
        "for col in categorical_cols:\n",
        "    data[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "print(data.info)\n",
        "print(data.head(10))\n",
        "print(data.dtypes)\n",
        "\n",
        "X = data.drop('NObeyesdad', axis=1)\n",
        "y = data['NObeyesdad']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThW1TiQx5SPB",
        "outputId": "3ec86372-1135-4431-c3df-d05abe64d480"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.info of       Gender        Age    Height      Weight  family_history_with_overweight  \\\n",
            "0          0  21.000000  1.620000   64.000000                               1   \n",
            "1          0  21.000000  1.520000   56.000000                               1   \n",
            "2          1  23.000000  1.800000   77.000000                               1   \n",
            "3          1  27.000000  1.800000   87.000000                               0   \n",
            "4          1  22.000000  1.780000   89.800000                               0   \n",
            "...      ...        ...       ...         ...                             ...   \n",
            "2106       0  20.976842  1.710730  131.408528                               1   \n",
            "2107       0  21.982942  1.748584  133.742943                               1   \n",
            "2108       0  22.524036  1.752206  133.689352                               1   \n",
            "2109       0  24.361936  1.739450  133.346641                               1   \n",
            "2110       0  23.664709  1.738836  133.472641                               1   \n",
            "\n",
            "      FAVC  FCVC  NCP  CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
            "0        0   2.0  3.0     2      0  2.000000    0  0.000000  1.000000     3   \n",
            "1        0   3.0  3.0     2      1  3.000000    1  3.000000  0.000000     2   \n",
            "2        0   2.0  3.0     2      0  2.000000    0  2.000000  1.000000     1   \n",
            "3        0   3.0  3.0     2      0  2.000000    0  2.000000  0.000000     1   \n",
            "4        0   2.0  1.0     2      0  2.000000    0  0.000000  0.000000     2   \n",
            "...    ...   ...  ...   ...    ...       ...  ...       ...       ...   ...   \n",
            "2106     1   3.0  3.0     2      0  1.728139    0  1.676269  0.906247     2   \n",
            "2107     1   3.0  3.0     2      0  2.005130    0  1.341390  0.599270     2   \n",
            "2108     1   3.0  3.0     2      0  2.054193    0  1.414209  0.646288     2   \n",
            "2109     1   3.0  3.0     2      0  2.852339    0  1.139107  0.586035     2   \n",
            "2110     1   3.0  3.0     2      0  2.863513    0  1.026452  0.714137     2   \n",
            "\n",
            "      MTRANS  NObeyesdad  \n",
            "0          3           1  \n",
            "1          3           1  \n",
            "2          3           1  \n",
            "3          4           5  \n",
            "4          3           6  \n",
            "...      ...         ...  \n",
            "2106       3           4  \n",
            "2107       3           4  \n",
            "2108       3           4  \n",
            "2109       3           4  \n",
            "2110       3           4  \n",
            "\n",
            "[2111 rows x 17 columns]>\n",
            "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
            "0       0  21.0    1.62    64.0                               1     0   2.0   \n",
            "1       0  21.0    1.52    56.0                               1     0   3.0   \n",
            "2       1  23.0    1.80    77.0                               1     0   2.0   \n",
            "3       1  27.0    1.80    87.0                               0     0   3.0   \n",
            "4       1  22.0    1.78    89.8                               0     0   2.0   \n",
            "5       1  29.0    1.62    53.0                               0     1   2.0   \n",
            "6       0  23.0    1.50    55.0                               1     1   3.0   \n",
            "7       1  22.0    1.64    53.0                               0     0   2.0   \n",
            "8       1  24.0    1.78    64.0                               1     1   3.0   \n",
            "9       1  22.0    1.72    68.0                               1     1   2.0   \n",
            "\n",
            "   NCP  CAEC  SMOKE  CH2O  SCC  FAF  TUE  CALC  MTRANS  NObeyesdad  \n",
            "0  3.0     2      0   2.0    0  0.0  1.0     3       3           1  \n",
            "1  3.0     2      1   3.0    1  3.0  0.0     2       3           1  \n",
            "2  3.0     2      0   2.0    0  2.0  1.0     1       3           1  \n",
            "3  3.0     2      0   2.0    0  2.0  0.0     1       4           5  \n",
            "4  1.0     2      0   2.0    0  0.0  0.0     2       3           6  \n",
            "5  3.0     2      0   2.0    0  0.0  0.0     2       0           1  \n",
            "6  3.0     2      0   2.0    0  1.0  0.0     2       2           1  \n",
            "7  3.0     2      0   2.0    0  3.0  0.0     2       3           1  \n",
            "8  3.0     2      0   2.0    0  1.0  1.0     1       3           1  \n",
            "9  3.0     2      0   2.0    0  1.0  1.0     3       3           1  \n",
            "Gender                              int64\n",
            "Age                               float64\n",
            "Height                            float64\n",
            "Weight                            float64\n",
            "family_history_with_overweight      int64\n",
            "FAVC                                int64\n",
            "FCVC                              float64\n",
            "NCP                               float64\n",
            "CAEC                                int64\n",
            "SMOKE                               int64\n",
            "CH2O                              float64\n",
            "SCC                                 int64\n",
            "FAF                               float64\n",
            "TUE                               float64\n",
            "CALC                                int64\n",
            "MTRANS                              int64\n",
            "NObeyesdad                          int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Separar dados para Treinamento e Teste"
      ],
      "metadata": {
        "id": "GusELrwZ7ZUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "XIh9-Rqz6zyJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Aplicar Algoritmos e Avaliar"
      ],
      "metadata": {
        "id": "jK2NNimu7e7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###√Årvore de Decis√£o"
      ],
      "metadata": {
        "id": "OIQmKQcs7lL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "y_pred_tree = tree_model.predict(X_test)\n",
        "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
        "f1_tree = f1_score(y_test, y_pred_tree, average='weighted')\n"
      ],
      "metadata": {
        "id": "85sc2vm-7jRQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bagging"
      ],
      "metadata": {
        "id": "-SGPvMcm7qxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "f1_bagging = f1_score(y_test, y_pred_bagging, average='weighted')\n"
      ],
      "metadata": {
        "id": "ZBKBuF_m7s-r"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Boosting(AdaBoost)"
      ],
      "metadata": {
        "id": "9bd32lpF7-u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adaboost_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=42)\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "y_pred_adaboost = adaboost_model.predict(X_test)\n",
        "acc_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
        "f1_adaboost = f1_score(y_test, y_pred_adaboost, average='weighted')\n"
      ],
      "metadata": {
        "id": "WJoaHQ2Z8Biu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "y_dEBSVH8Wgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n"
      ],
      "metadata": {
        "id": "RPxYoTKR8ZgW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Avalia√ß√£o do melhor resultado"
      ],
      "metadata": {
        "id": "Drwahb-e8cJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    '√Årvore de Decis√£o': (acc_tree, f1_tree),\n",
        "    'Bagging': (acc_bagging, f1_bagging),\n",
        "    'AdaBoost': (acc_adaboost, f1_adaboost),\n",
        "    'Random Forest': (acc_rf, f1_rf)\n",
        "}\n",
        "\n",
        "for model, scores in results.items():\n",
        "    print(f\"{model} -> Acur√°cia: {scores[0]:.4f}, F1: {scores[1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zszOoSQc8eth",
        "outputId": "e3cb5cce-f3cd-448c-a5fe-e39e0445ff00"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "√Årvore de Decis√£o -> Acur√°cia: 0.9148, F1: 0.9145\n",
            "Bagging -> Acur√°cia: 0.9432, F1: 0.9431\n",
            "AdaBoost -> Acur√°cia: 0.9085, F1: 0.9079\n",
            "Random Forest -> Acur√°cia: 0.9432, F1: 0.9437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ajuste de Hiperpar√¢metros no melhor modelo\n",
        "\n",
        "O melhor modelo encontrado foi de Random Forest"
      ],
      "metadata": {
        "id": "uiXr_0j-8sy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajuste de Hiperpar√¢metros na Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "acc_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "f1_best_rf = f1_score(y_test, y_pred_best_rf, average='weighted')\n",
        "\n",
        "print(f\"Melhor Random Forest -> Acur√°cia: {acc_best_rf:.4f}, F1: {f1_best_rf:.4f}\")\n"
      ],
      "metadata": {
        "id": "8ZhpNZJy80LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Abordagens OVA e OVO"
      ],
      "metadata": {
        "id": "8BjyIWIa9uqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OVA (One-vs-One): Transforme o problema multiclasse em problemas bin√°rios usando a estrat√©gia One-vs-All. Isso significa que, para cada classe, voc√™ vai treinar um classificador que separa essa classe de todas as outras."
      ],
      "metadata": {
        "id": "zKIw4bQo9zmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ova_model = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ova_model.fit(X_train, y_train)\n",
        "y_pred_ova = ova_model.predict(X_test)\n",
        "acc_ova = accuracy_score(y_test, y_pred_ova)\n",
        "f1_ova = f1_score(y_test, y_pred_ova, average='weighted')\n"
      ],
      "metadata": {
        "id": "ZxLzh64k95a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###OVO (One-vs-One): Para a abordagem One-vs-One, voc√™ vai treinar um classificador para cada par de classes. Por exemplo, para tr√™s classes A, B, e C, voc√™ criar√° classificadores para A vs B, A vs C, e B vs C."
      ],
      "metadata": {
        "id": "Ru-60OZf97ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ovo_model = OneVsOneClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "y_pred_ovo = ovo_model.predict(X_test)\n",
        "acc_ovo = accuracy_score(y_test, y_pred_ovo)\n",
        "f1_ovo = f1_score(y_test, y_pred_ovo, average='weighted')\n"
      ],
      "metadata": {
        "id": "VmCi717H9_DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compara√ß√£o das duas abordagens"
      ],
      "metadata": {
        "id": "pZXjd9ap-BEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"OVA -> Acur√°cia: {acc_ova:.4f}, F1: {f1_ova:.4f}\")\n",
        "print(f\"OVO -> Acur√°cia: {acc_ovo:.4f}, F1: {f1_ovo:.4f}\")\n"
      ],
      "metadata": {
        "id": "-ZbrdHQ4-Et1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An√°lise de Resultados para OVA e OVO\n",
        "\n",
        "## 1. Introdu√ß√£o\n",
        "\n",
        "A seguir, s√£o apresentados os resultados da aplica√ß√£o das t√©cnicas OVA (One-vs-All) e OVO (One-vs-One) utilizando um classificador de √°rvore de decis√£o. Para avaliar o desempenho dessas duas abordagens, foram utilizadas as m√©tricas de **acur√°cia** e **F1-Score**.\n",
        "\n",
        "## 2. Resultados Obtidos\n",
        "\n",
        "- **OVA** (One-vs-All)  \n",
        "  - Acur√°cia: **0.8644**  \n",
        "  - F1-Score: **0.8688**\n",
        "\n",
        "- **OVO** (One-vs-One)  \n",
        "  - Acur√°cia: **0.9006**  \n",
        "  - F1-Score: **0.9006**\n",
        "\n",
        "## 3. Discuss√£o dos Resultados\n",
        "\n",
        "### 3.1. Desempenho da Abordagem OVA ü§î\n",
        "\n",
        "Na abordagem **OVA (One-vs-All)**, o modelo de √°rvore de decis√£o obteve uma acur√°cia de **86.44%** e um F1-Score de **86.88%**. Embora seja um desempenho razo√°vel, podemos observar que o modelo teve dificuldades em capturar com precis√£o as distin√ß√µes entre todas as classes ao trat√°-las de forma individual contra as demais. A t√©cnica OVA tende a ser menos eficiente para problemas com muitas classes, pois o modelo precisa diferenciar uma classe contra todas as outras, o que pode gerar confus√£o entre classes pr√≥ximas.\n",
        "\n",
        "### 3.2. Desempenho da Abordagem OVO üí°\n",
        "\n",
        "Por outro lado, a abordagem **OVO (One-vs-One)** apresentou uma **melhoria significativa** em ambas as m√©tricas, com acur√°cia de **90.06%** e F1-Score de **90.06%**. Esse ganho de desempenho pode ser atribu√≠do ao fato de que, no OVO, o modelo constr√≥i classificadores para cada par de classes, resultando em uma maior capacidade de separar classes adjacentes de forma mais precisa. Isso reduz a confus√£o entre as classes e leva a um desempenho superior no conjunto de teste.\n",
        "\n",
        "### 3.3. Compara√ß√£o OVA vs OVO üîÑ\n",
        "\n",
        "Comparando as duas abordagens, a t√©cnica **OVO** se mostrou superior tanto em termos de acur√°cia quanto de F1-Score. A abordagem **OVA** simplifica o problema, mas acaba perdendo efici√™ncia na separa√ß√£o das classes. J√° a abordagem **OVO**, embora mais complexa, consegue um desempenho **mais robusto**, especialmente em problemas multiclasse como este, onde as classes possuem caracter√≠sticas similares.\n",
        "\n",
        "## 4. Conclus√£o ‚úÖ\n",
        "\n",
        "Os resultados indicam que, para o dataset utilizado, a t√©cnica **One-vs-One (OVO)** √© a mais adequada, pois oferece melhor desempenho ao tratar as classes de forma mais detalhada, gerando menos confus√£o entre elas. Portanto, a abordagem OVO √© a recomendada para este problema de classifica√ß√£o multiclasse.\n"
      ],
      "metadata": {
        "id": "PX6pPdxfwFw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Matriz de confus√£o para OVA\n",
        "cm_ova = confusion_matrix(y_test, y_pred_ova)\n",
        "\n",
        "# Plot da matriz de confus√£o\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_ova, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confus√£o OVA')\n",
        "plt.xlabel('Classe Prevista')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confus√£o para OVO\n",
        "cm_ovo = confusion_matrix(y_test, y_pred_ovo)\n",
        "\n",
        "# Plot da matriz de confus√£o\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_ovo, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confus√£o OVO')\n",
        "plt.xlabel('Classe Prevista')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9xoMvvNFwGcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An√°lise das Matrizes de Confus√£o\n",
        "\n",
        "\n",
        "As matrizes de confus√£o s√£o uma excelente ferramenta para analisar o desempenho de um classificador, fornecendo uma vis√£o detalhada das previs√µes corretas e incorretas. A seguir, s√£o discutidas as matrizes de confus√£o geradas para as abordagens **OVA (One-vs-All)** e **OVO (One-vs-One)**.\n",
        "\n",
        "## 1. Matriz de Confus√£o OVA ü§î\n",
        "\n",
        "A matriz de confus√£o da abordagem **OVA** (One-vs-All) mostra que, embora o classificador tenha tido um desempenho geral satisfat√≥rio, existem algumas confus√µes not√°veis entre as classes:\n",
        "\n",
        "- A classe **1 (Normal Weight)** foi frequentemente confundida com as classes **5** e **6** (Obesity Type II e III), com **18 previs√µes erradas**. Isso indica que o modelo teve dificuldades em distinguir entre essas classes de maior obesidade.\n",
        "- A classe **5 (Obesity Type II)** foi prevista corretamente **64 vezes**, mas foi confundida com a classe **6** em **18 inst√¢ncias**. Isso √© esperado, j√° que essas classes representam est√°gios avan√ßados de obesidade, o que pode gerar uma sobreposi√ß√£o nas caracter√≠sticas preditivas.\n",
        "- Para a classe **0 (Insufficient Weight)**, o modelo acertou a maioria das previs√µes (**79 previs√µes corretas**), mas houve **5 confus√µes com a classe 6 (Obesity Type III)**, o que sugere uma certa dificuldade em distinguir entre extremos opostos do espectro.\n",
        "\n",
        "### 1.1. Conclus√£o OVA\n",
        "\n",
        "O classificador OVA tem uma tend√™ncia a confundir classes adjacentes ou opostas, como **Insufficient Weight** e **Obesity Type III**, e classes intermedi√°rias de obesidade (**Obesity Type II e III**). Isso pode indicar que o modelo OVA n√£o √© capaz de capturar nuances espec√≠ficas entre classes multiclasse.\n",
        "\n",
        "## 2. Matriz de Confus√£o OVO üí°\n",
        "\n",
        "A matriz de confus√£o da abordagem **OVO** (One-vs-One) apresenta um desempenho ligeiramente superior em compara√ß√£o com a abordagem OVA:\n",
        "\n",
        "- A classe **1 (Normal Weight)** teve um desempenho melhor, com **77 previs√µes corretas**, mas ainda houve confus√£o com as classes **5** e **6**, com **12 e 3 previs√µes erradas**, respectivamente.\n",
        "- A classe **5 (Obesity Type II)**, que foi uma das mais confusas no OVA, melhorou seu desempenho aqui, com **73 previs√µes corretas** e **8 confus√µes com a classe 6**. Ainda assim, essa confus√£o √© esperada devido √†s semelhan√ßas entre os dois tipos de obesidade.\n",
        "- A classe **0 (Insufficient Weight)** foi prevista corretamente **82 vezes**, o que representa um pequeno aumento de desempenho em rela√ß√£o ao OVA. A confus√£o com a classe **6 (Obesity Type III)** diminuiu significativamente, com apenas **2 previs√µes incorretas**, mostrando que o modelo OVO foi mais eficiente ao lidar com os extremos do espectro.\n",
        "\n",
        "### 2.1. Conclus√£o OVO\n",
        "\n",
        "A abordagem **OVO** claramente melhora a capacidade do modelo de separar classes semelhantes, como visto nas menores confus√µes entre as classes intermedi√°rias e extremas. O modelo consegue capturar melhor as diferen√ßas entre as classes, resultando em uma matriz de confus√£o mais limpa e com menos confus√µes.\n",
        "\n",
        "## 3. Compara√ß√£o Geral üîÑ\n",
        "\n",
        "- **OVA** mostrou confus√µes significativas entre classes intermedi√°rias e classes opostas, como **Insufficient Weight** e **Obesity Type III**.\n",
        "- **OVO** reduziu essas confus√µes, principalmente entre as classes **Insufficient Weight** e **Obesity Type III**, e melhorou a separa√ß√£o das classes intermedi√°rias, como **Obesity Type II** e **Obesity Type III**.\n",
        "\n",
        "Com base nas matrizes de confus√£o, podemos concluir que a abordagem **OVO** oferece um desempenho superior em termos de separa√ß√£o de classes e reduz a taxa de confus√µes entre as classes mais semelhantes.\n",
        "\n",
        "## 4. Conclus√£o Final üìå\n",
        "\n",
        "A an√°lise das matrizes de confus√£o confirma os resultados anteriores, indicando que a abordagem **OVO** (One-vs-One) √© a mais eficaz para este problema multiclasse. O modelo conseguiu separar melhor as classes, reduzindo a confus√£o entre elas, especialmente para as classes mais semelhantes, como os diferentes tipos de obesidade.\n"
      ],
      "metadata": {
        "id": "FKpcCOa_xUNW"
      }
    }
  ]
}